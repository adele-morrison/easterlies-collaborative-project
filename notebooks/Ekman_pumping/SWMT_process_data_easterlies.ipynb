{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMT variability in easterly simulations, calculations to save diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cosima_cookbook as cc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs\n",
    "import xarray as xr\n",
    "import cmocean.cm as cmocean\n",
    "import glob\n",
    "from gsw import alpha, SA_from_SP, p_from_z, CT_from_pt, beta, sigma0,sigma1\n",
    "\n",
    "import logging\n",
    "logging.captureWarnings(True)\n",
    "logging.getLogger('py.warnings').setLevel(logging.ERROR)\n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "#figdir = '/g/data/v45/akm157/figures/Weddell_connectivity/SWMT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:34309</li>\n",
       "  <li><b>Dashboard: </b><a href='/proxy/34515/status' target='_blank'>/proxy/34515/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>100.00 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:34309' processes=4 threads=4, memory=100.00 GiB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client = Client(n_workers=4)\n",
    "# >> dask-scheduler\n",
    "# >> dask-worker tcp://10.0.64.9:8786 --memory-limit 4e9 --nprocs 6 --nthreads 1 --local-directory /local/g40/amh157\n",
    "#client = Client('tcp://10.0.64.9:8786', local_dir='/local/g40/amh157')\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97d012de2d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmaster_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/g/data/ik11/databases/cosima_master.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'01deg_jra55v13_ryf9091'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2150-01-01'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2164-12-31'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cc' is not defined"
     ]
    }
   ],
   "source": [
    "master_session = cc.database.create_session('/g/data/ik11/databases/cosima_master.db')\n",
    "control = '01deg_jra55v13_ryf9091'\n",
    "\n",
    "start_time='2150-01-01'\n",
    "end_time='2164-12-31'\n",
    "end_time='2151-12-31'\n",
    "# just 5 years:\n",
    "#start_time='2155-01-01'\n",
    "#end_time='2159-12-31'\n",
    "\n",
    "time_period = str(int(start_time[:4]))+'-'+str(int(end_time[:4]))\n",
    "\n",
    "lat_slice  = slice(-78.5,-64)\n",
    "\n",
    "##### NOTE: I was having memory troubles running this all in one go, so I've split into two sections. \n",
    "# The script needs to be run twice for the two longitude ranges, and each time change the name of the file it is saved to.\n",
    "\n",
    "#region = 'east'\n",
    "region = 'west'\n",
    "if region == 'west':\n",
    "    # Just cover Mertz and Ross, save as west:\n",
    "    lon_slice  = slice(-280, -100)\n",
    "elif region == 'east':\n",
    "    # Just cover Weddell and Prydz, save as east:\n",
    "    lon_slice  = slice(-100, 80)\n",
    "\n",
    "#region = 'Weddell'\n",
    "# zoom into just Weddell DSW region:\n",
    "#lat_slice  = slice(-78.5,-70)\n",
    "#lon_slice  = slice(-62, -28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name = '/g/data/v45/akm157/model_data/access-om2/01deg_jra55v13_ryf9091_easterlies_up10/easterlies.db'\n",
    "easterlies_session = cc.database.create_session(session_name)\n",
    "\n",
    "easterlies_up = '01deg_jra55v13_ryf9091_easterlies_up10'\n",
    "easterlies_up_noDSW = '01deg_jra55v13_ryf9091_easterlies_up10_noDSW'\n",
    "easterlies_down = '01deg_jra55v13_ryf9091_easterlies_down10'\n",
    "easterlies_up_zonal = '01deg_jra55v13_ryf9091_easterlies_up10_zonal'\n",
    "easterlies_up_meridional = '01deg_jra55v13_ryf9091_easterlies_up10_meridional'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shelf masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shelf_mask_isobath(var):\n",
    "    contour_file = np.load('/g/data/ik11/grids/Antarctic_slope_contour_1000m.npz')\n",
    "    shelf_mask = contour_file['contour_masked_above']\n",
    "    yt_ocean = contour_file['yt_ocean']\n",
    "    xt_ocean = contour_file['xt_ocean']\n",
    "    # Mask values that are non-zero\n",
    "    shelf_mask[np.where(shelf_mask!=0)] = np.nan\n",
    "    shelf_mask = shelf_mask+1\n",
    "    shelf_map = np.nan_to_num(shelf_mask)\n",
    "    shelf_mask = xr.DataArray(shelf_mask, coords = [('yt_ocean', yt_ocean), ('xt_ocean', xt_ocean)])\n",
    "    shelf_map = xr.DataArray(shelf_map, coords = [('yt_ocean', yt_ocean), ('xt_ocean', xt_ocean)])\n",
    "    # Multiply the variable with the mask, we need to account for the shape of the mask. \n",
    "    # The mask uses a northern cutoff of 59S.\n",
    "    masked_var = var.sel(yt_ocean = slice(-90, -59.03)) * shelf_mask\n",
    "    return masked_var, shelf_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative temperature\n",
    "SST = cc.querying.getvar(control, 'surface_temp', master_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) - 273.15\n",
    "SST = SST.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Practical salinity, need to convert to absolute salinity\n",
    "SSS_PSU = cc.querying.getvar(control, 'surface_salt', master_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "SSS_PSU = SSS_PSU.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Unfortunately net_sfc_heating diagnostic is incorrect/missing for these runs:\n",
    "#net_sfc_heating = cc.querying.getvar(control, 'net_sfc_heating', master_session, start_time=start_time, end_time=end_time)\n",
    "#net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "net_sfc_heating = cc.querying.getvar(control, 'sfc_hflux_from_runoff', master_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(control, 'sfc_hflux_coupler', master_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(control, 'sfc_hflux_pme', master_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(control, 'frazil_3d_int_z', master_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc')\n",
    "net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Mass flux of precipitation - evaporation + river runoff\n",
    "pme_river = cc.querying.getvar(control, 'pme_river', master_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "pme_river = pme_river.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Salt flux from ice and restoring:\n",
    "salt_flux = cc.querying.getvar(control, 'sfc_salt_flux_ice', master_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) + \\\n",
    "            cc.querying.getvar(control, 'sfc_salt_flux_restore', master_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "salt_flux = salt_flux.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Surface density:\n",
    "pot_rho_0 = cc.querying.getvar(control, 'pot_rho_0', master_session, ncfile='ocean.nc',start_time=start_time, end_time=end_time) - 1000\n",
    "pot_rho_0 = pot_rho_0.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice).sel(st_ocean=0,method='nearest')\n",
    "\n",
    "# Coordinates\n",
    "lon_t = cc.querying.getvar(control,'geolon_t',master_session, n=1)\n",
    "lon_t = lon_t.sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "lat_t = cc.querying.getvar(control,'geolat_t',master_session, n=1)\n",
    "lat_t = lat_t.sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to continental shelf region:\n",
    "SST  = shelf_mask_isobath(SST)[0]\n",
    "SSS_PSU = shelf_mask_isobath(SSS_PSU)[0]\n",
    "pot_rho_0 = shelf_mask_isobath(pot_rho_0)[0]\n",
    "net_sfc_heating = shelf_mask_isobath(net_sfc_heating)[0]\n",
    "pme_river = shelf_mask_isobath(pme_river)[0]\n",
    "salt_flux = shelf_mask_isobath(salt_flux)[0]\n",
    "lon_t   = shelf_mask_isobath(lon_t)[0]\n",
    "lat_t   = shelf_mask_isobath(lat_t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinate arrays:\n",
    "yt_ocean = SST.yt_ocean.values\n",
    "xt_ocean = SST.xt_ocean.values\n",
    "time_monthly = SST.time.values\n",
    "\n",
    "# Construct an xarray of days per month:\n",
    "n_days_array = cc.querying.getvar(control,'time_bounds',master_session,\n",
    "                 start_time=start_time, end_time=end_time,ncfile='ocean.nc')\n",
    "n_days_array = n_days_array.sel(time=slice(start_time,end_time))\n",
    "n_days_array = (n_days_array.isel(nv=1) - n_days_array.isel(nv=0))/60/60/24/1e9\n",
    "n_days_array = n_days_array.astype('int64')\n",
    "\n",
    "# Create an array with years:\n",
    "time_yearly = np.arange(int(start_time[0:4]), int(start_time[0:4])+len(SST.time)/12, 1).astype('int')\n",
    "n_years = len(time_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to absolute salinity:\n",
    "\n",
    "st_ocean = cc.querying.getvar(control,'st_ocean',master_session,n=1)\n",
    "depth = st_ocean[0].values\n",
    "depth_tile = (lat_t*0+1)*depth\n",
    "pressure = xr.DataArray(p_from_z(depth_tile,lat_t), coords = [yt_ocean, xt_ocean], dims = ['yt_ocean', 'xt_ocean'], name = 'pressure', attrs = {'units':'dbar'})\n",
    "    \n",
    "# convert units to absolute salinity \n",
    "SSS = xr.DataArray(SA_from_SP(SSS_PSU,pressure,lon_t,lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'sea surface salinity', attrs = {'units':'Absolute Salinity (g/kg)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute salt transformation (no density binning)\n",
    "haline_contraction  = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "salt_transformation = haline_contraction * SSS * (pme_river - salt_flux) * n_days_array\n",
    "salt_transformation = salt_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_days_array.time\n",
    "yt_ocean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute heat transformation (no density binning)\n",
    "thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "heat_transformation = thermal_expansion * net_sfc_heating * n_days_array\n",
    "heat_transformation = heat_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (time: 24, yt_ocean: 343, xt_ocean: 1800)&gt;\n",
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])\n",
       "Coordinates:\n",
       "  * time      (time) object 2150-01-16 12:00:00 ... 2151-12-16 12:00:00\n",
       "  * yt_ocean  (yt_ocean) float64 -78.49 -78.45 -78.41 ... -64.11 -64.07 -64.03\n",
       "  * xt_ocean  (xt_ocean) float64 -99.95 -99.85 -99.75 ... 79.75 79.85 79.95</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 24</li><li><span class='xr-has-index'>yt_ocean</span>: 343</li><li><span class='xr-has-index'>xt_ocean</span>: 1800</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-b43d55a4-c13c-4fdd-8c0e-27ff9bb625c2' class='xr-array-in' type='checkbox' checked><label for='section-b43d55a4-c13c-4fdd-8c0e-27ff9bb625c2' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>nan nan nan nan nan nan nan nan ... nan nan nan nan nan nan nan nan</span></div><div class='xr-array-data'><pre>array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])</pre></div></div></li><li class='xr-section-item'><input id='section-f4957713-b5da-47ba-9d89-303e4e7a672a' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f4957713-b5da-47ba-9d89-303e4e7a672a' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>2150-01-16 12:00:00 ... 2151-12-...</div><input id='attrs-53a4bd26-b9d2-4073-bba5-3075e875c4cd' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-53a4bd26-b9d2-4073-bba5-3075e875c4cd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-00d5ca4c-173d-4e08-8be6-6615d79544fc' class='xr-var-data-in' type='checkbox'><label for='data-00d5ca4c-173d-4e08-8be6-6615d79544fc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([cftime.DatetimeNoLeap(2150, 1, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 2, 15, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 3, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 4, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 5, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 6, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 7, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 8, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 9, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 10, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 11, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2150, 12, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 1, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 2, 15, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 3, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 4, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 5, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 6, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 7, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 8, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 9, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 10, 16, 12, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 11, 16, 0, 0, 0, 0),\n",
       "       cftime.DatetimeNoLeap(2151, 12, 16, 12, 0, 0, 0)], dtype=object)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>yt_ocean</span></div><div class='xr-var-dims'>(yt_ocean)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-78.49 -78.45 ... -64.07 -64.03</div><input id='attrs-e657f500-95ed-4865-a889-894fbcdeaaec' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-e657f500-95ed-4865-a889-894fbcdeaaec' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d615c3e8-9a81-4838-ae12-efcbfa7079b3' class='xr-var-data-in' type='checkbox'><label for='data-d615c3e8-9a81-4838-ae12-efcbfa7079b3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-78.489792, -78.447552, -78.405313, ..., -64.113591, -64.069898,\n",
       "       -64.026136])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>xt_ocean</span></div><div class='xr-var-dims'>(xt_ocean)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-99.95 -99.85 ... 79.85 79.95</div><input id='attrs-6f8abd13-9fb8-4bd9-bacc-0959f6b3dba9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-6f8abd13-9fb8-4bd9-bacc-0959f6b3dba9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f0dbe70a-8a69-4654-be79-7e587210d9d0' class='xr-var-data-in' type='checkbox'><label for='data-f0dbe70a-8a69-4654-be79-7e587210d9d0' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([-99.95, -99.85, -99.75, ...,  79.75,  79.85,  79.95])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8dc323fc-0309-487f-bbdc-751aab2bb491' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-8dc323fc-0309-487f-bbdc-751aab2bb491' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray (time: 24, yt_ocean: 343, xt_ocean: 1800)>\n",
       "array([[[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]],\n",
       "\n",
       "       [[nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan],\n",
       "        [nan, nan, nan, ..., nan, nan, nan]]])\n",
       "Coordinates:\n",
       "  * time      (time) object 2150-01-16 12:00:00 ... 2151-12-16 12:00:00\n",
       "  * yt_ocean  (yt_ocean) float64 -78.49 -78.45 -78.41 ... -64.11 -64.07 -64.03\n",
       "  * xt_ocean  (xt_ocean) float64 -99.95 -99.85 -99.75 ... 79.75 79.85 79.95"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salt_transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2150 done\n",
      "Year 2151 done\n"
     ]
    }
   ],
   "source": [
    "# Density binning sigma0:\n",
    "\n",
    "# Alter if density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "# sigma1:\n",
    "#isopycnal_bins = np.arange(32.25, 32.75, 0.01) \n",
    "# sigma0:\n",
    "isopycnal_bins = np.arange(27.5, 28.1, 0.04)\n",
    "\n",
    "bin_bottoms = isopycnal_bins[:-1]\n",
    "\n",
    "binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "for tt in range(n_years):\n",
    "    start_t = str(time_yearly[tt]) + '-01-01'\n",
    "    end_t   = str(time_yearly[tt]) + '-12-31'\n",
    "    salt_transformation_tmp = salt_transformation.sel(time=slice(start_t, end_t))\n",
    "    heat_transformation_tmp = heat_transformation.sel(time=slice(start_t, end_t))\n",
    "    pot_rho_0_tmp = pot_rho_0.sel(time=slice(start_t, end_t))\n",
    "                                                      \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_0_tmp.where(pot_rho_0_tmp <= isopycnal_bins[i+1]).where(pot_rho_0_tmp > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i,tt,:,:] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i,tt,:,:] = masked_transform\n",
    "    print('Year %i done'%time_yearly[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'/g/data/v45/akm157/model_data/access-om2/01deg_jra55v13_ryf9091/SWMT/east_shelf_transformation_sigma0_2150-2151.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/g/data/v45/akm157/model_data/access-om2/01deg_jra55v13_ryf9091/SWMT/east_shelf_transformation_sigma0_2150-2151.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-52ec5eb49db4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'net_transformation_control'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnet_transformation_control\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0moutpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/g/data/v45/akm157/model_data/access-om2/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/SWMT/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_shelf_transformation_sigma0_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtime_period\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.nc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_netcdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1799\u001b[0;31m         return to_netcdf(\n\u001b[0m\u001b[1;32m   1800\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1801\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 \u001b[0;34mf\"unrecognized option 'invalid_netcdf' for engine {engine}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             )\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munlimited_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         )\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m# ensure file doesn't get overriden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'/g/data/v45/akm157/model_data/access-om2/01deg_jra55v13_ryf9091/SWMT/east_shelf_transformation_sigma0_2150-2151.nc'"
     ]
    }
   ],
   "source": [
    "# calculate transformation sigma0:\n",
    "\n",
    "c_p = 3992.1\n",
    "isopycnal_bin_diff  = np.diff(isopycnal_bins)\n",
    "isopycnal_bin_mid   = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "\n",
    "# Will be overwritten in loop, this is just to get the dimensions etc\n",
    "salt_transformation_sigma0 = binned_salt_transformation\n",
    "heat_transformation_sigma0 = binned_heat_transformation\n",
    "\n",
    "salt_transformation_tmp = binned_salt_transformation / 365.\n",
    "heat_transformation_tmp = binned_heat_transformation / c_p / 365.\n",
    "\n",
    "# This procedure defines fluxes from lighter to denser classes as negative, we want the opposite\n",
    "salt_transformation_sigma0 = -1*salt_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "heat_transformation_sigma0 = -1*heat_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "# Convert the binned (and summed through time) salt and heat transformation DataArrays to Datasets (to save metadata) and save to netCDF\n",
    "#ds = xr.Dataset({'binned_salt_transformation': salt_transformation})\n",
    "#ds = xr.Dataset({'binned_heat_transformation': heat_transformation})\n",
    "\n",
    "#############################################################\n",
    "net_transformation_control = heat_transformation_sigma0 + salt_transformation_sigma0\n",
    "#############################################################\n",
    "\n",
    "# Rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "net_transformation_control.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "ds = xr.Dataset({'net_transformation_control': net_transformation_control})\n",
    "outpath = '/g/data/v45/pas561/jnb/easterlies-collaborative-project/notebooks/Ekman_pumping/'+region+'_shelf_transformation_sigma0_'+time_period+'.nc'\n",
    "ds.to_netcdf(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 697, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 893, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 558, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 22411698181952 and this is thread id 22409090426624.\n",
      "Exception closing connection <sqlite3.Connection object at 0x1461851e8990>\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 697, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 893, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 558, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 22411698181952 and this is thread id 22409090426624.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/pool/base.py\", line 270, in _close_connection\n",
      "    self._dialect.do_close(connection)\n",
      "  File \"/g/data3/hh5/public/apps/miniconda3/envs/analysis3-21.04/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 564, in do_close\n",
      "    dbapi_connection.close()\n",
      "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 22411698181952 and this is thread id 22409090426624.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# conservative temperature\n",
    "SST = cc.querying.getvar(easterlies_up, 'surface_temp', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) - 273.15\n",
    "SST = SST.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Practical salinity, need to convert to absolute salinity\n",
    "SSS_PSU = cc.querying.getvar(easterlies_up, 'surface_salt', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "SSS_PSU = SSS_PSU.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Unfortunately net_sfc_heating diagnostic is incorrect/missing for these runs:\n",
    "#net_sfc_heating = cc.querying.getvar(easterlies_up, 'net_sfc_heating', easterlies_session, start_time=start_time, end_time=end_time)\n",
    "#net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "net_sfc_heating = cc.querying.getvar(easterlies_up, 'sfc_hflux_from_runoff', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up, 'sfc_hflux_coupler', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up, 'sfc_hflux_pme', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up, 'frazil_3d_int_z', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc')\n",
    "net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Mass flux of precipitation - evaporation + river runoff\n",
    "pme_river = cc.querying.getvar(easterlies_up, 'pme_river', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "pme_river = pme_river.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Salt flux from ice and restoring:\n",
    "salt_flux = cc.querying.getvar(easterlies_up, 'sfc_salt_flux_ice', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) + \\\n",
    "            cc.querying.getvar(easterlies_up, 'sfc_salt_flux_restore', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "salt_flux = salt_flux.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Surface density:\n",
    "pot_rho_0 = cc.querying.getvar(easterlies_up, 'pot_rho_0', easterlies_session, ncfile='ocean.nc',start_time=start_time, end_time=end_time) - 1000\n",
    "pot_rho_0 = pot_rho_0.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice).sel(st_ocean=0,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_monthly = SST.time.values\n",
    "\n",
    "# Construct an xarray of days per month:\n",
    "n_days_array = cc.querying.getvar(control,'time_bounds',master_session,\n",
    "                 start_time=start_time, end_time=end_time,ncfile='ocean.nc')\n",
    "n_days_array = n_days_array.sel(time=slice(start_time,end_time))\n",
    "n_days_array = (n_days_array.isel(nv=1) - n_days_array.isel(nv=0))/60/60/24/1e9\n",
    "n_days_array = n_days_array.astype('int64')\n",
    "\n",
    "# Create an array with years:\n",
    "time_yearly = np.arange(int(start_time[0:4]), int(start_time[0:4])+ n_years, 1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to continental shelf region:\n",
    "SST  = shelf_mask_isobath(SST)[0]\n",
    "SSS_PSU = shelf_mask_isobath(SSS_PSU)[0]\n",
    "pot_rho_0 = shelf_mask_isobath(pot_rho_0)[0]\n",
    "net_sfc_heating = shelf_mask_isobath(net_sfc_heating)[0]\n",
    "pme_river = shelf_mask_isobath(pme_river)[0]\n",
    "salt_flux = shelf_mask_isobath(salt_flux)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to absolute salinity:\n",
    "# convert units to absolute salinity \n",
    "SSS = xr.DataArray(SA_from_SP(SSS_PSU,pressure,lon_t,lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'sea surface salinity', attrs = {'units':'Absolute Salinity (g/kg)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute salt transformation (no density binning)\n",
    "haline_contraction  = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "salt_transformation = haline_contraction * SSS * (pme_river - salt_flux) * n_days_array\n",
    "salt_transformation = salt_transformation.load()\n",
    "\n",
    "# Compute heat transformation (no density binning)\n",
    "thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "heat_transformation = thermal_expansion * net_sfc_heating * n_days_array\n",
    "heat_transformation = heat_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2150 done\n",
      "Year 2151 done\n",
      "Year 2152 done\n",
      "Year 2153 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2154 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2155 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2156 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2157 done\n",
      "Year 2158 done\n",
      "Year 2159 done\n",
      "Year 2160 done\n",
      "Year 2161 done\n",
      "Year 2162 done\n",
      "Year 2163 done\n",
      "Year 2164 done\n"
     ]
    }
   ],
   "source": [
    "# Density binning sigma0:\n",
    "\n",
    "# Alter if density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "# sigma1:\n",
    "#isopycnal_bins = np.arange(32.25, 32.75, 0.01) \n",
    "# sigma0:\n",
    "isopycnal_bins = np.arange(27.5, 28.1, 0.04)\n",
    "\n",
    "bin_bottoms = isopycnal_bins[:-1]\n",
    "\n",
    "binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "for tt in range(n_years):\n",
    "    start_t = str(time_yearly[tt]) + '-01-01'\n",
    "    end_t   = str(time_yearly[tt]) + '-12-31'\n",
    "    salt_transformation_tmp = salt_transformation.sel(time=slice(start_t, end_t))\n",
    "    heat_transformation_tmp = heat_transformation.sel(time=slice(start_t, end_t))\n",
    "    pot_rho_0_tmp = pot_rho_0.sel(time=slice(start_t, end_t))\n",
    "                                                      \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_0_tmp.where(pot_rho_0_tmp <= isopycnal_bins[i+1]).where(pot_rho_0_tmp > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i,tt,:,:] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i,tt,:,:] = masked_transform\n",
    "    print('Year %i done'%time_yearly[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transformation sigma0:\n",
    "\n",
    "c_p = 3992.1\n",
    "isopycnal_bin_diff  = np.diff(isopycnal_bins)\n",
    "isopycnal_bin_mid   = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "\n",
    "# Will be overwritten in loop, this is just to get the dimensions etc\n",
    "salt_transformation_sigma0 = binned_salt_transformation\n",
    "heat_transformation_sigma0 = binned_heat_transformation\n",
    "\n",
    "salt_transformation_tmp = binned_salt_transformation / 365.\n",
    "heat_transformation_tmp = binned_heat_transformation / c_p / 365.\n",
    "\n",
    "# This procedure defines fluxes from lighter to denser classes as negative, we want the opposite\n",
    "salt_transformation_sigma0 = -1*salt_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "heat_transformation_sigma0 = -1*heat_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "#############################################################\n",
    "net_transformation_up1 = heat_transformation_sigma0 + salt_transformation_sigma0\n",
    "#############################################################\n",
    "\n",
    "# Rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "net_transformation_up1.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "ds = xr.Dataset({'net_transformation_up1': net_transformation_up1})\n",
    "outpath = '/g/data/v45/akm157/model_data/access-om2/'+easterlies_up+'/SWMT/'+region+'_shelf_transformation_sigma0_'+time_period+'.nc'\n",
    "ds.to_netcdf(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up noDSW perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative temperature\n",
    "SST = cc.querying.getvar(easterlies_up_noDSW, 'surface_temp', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) - 273.15\n",
    "SST = SST.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Practical salinity, need to convert to absolute salinity\n",
    "SSS_PSU = cc.querying.getvar(easterlies_up_noDSW, 'surface_salt', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "SSS_PSU = SSS_PSU.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Unfortunately net_sfc_heating diagnostic is incorrect/missing for these runs:\n",
    "#net_sfc_heating = cc.querying.getvar(easterlies_up_noDSW, 'net_sfc_heating', easterlies_session, start_time=start_time, end_time=end_time)\n",
    "#net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "net_sfc_heating = cc.querying.getvar(easterlies_up_noDSW, 'sfc_hflux_from_runoff', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_noDSW, 'sfc_hflux_coupler', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_noDSW, 'sfc_hflux_pme', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_noDSW, 'frazil_3d_int_z', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc')\n",
    "net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Mass flux of precipitation - evaporation + river runoff\n",
    "pme_river = cc.querying.getvar(easterlies_up_noDSW, 'pme_river', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "pme_river = pme_river.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Salt flux from ice and restoring:\n",
    "salt_flux = cc.querying.getvar(easterlies_up_noDSW, 'sfc_salt_flux_ice', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) + \\\n",
    "            cc.querying.getvar(easterlies_up_noDSW, 'sfc_salt_flux_restore', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "salt_flux = salt_flux.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Surface density:\n",
    "pot_rho_0 = cc.querying.getvar(easterlies_up_noDSW, 'pot_rho_0', easterlies_session, ncfile='ocean.nc',start_time=start_time, end_time=end_time) - 1000\n",
    "pot_rho_0 = pot_rho_0.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice).sel(st_ocean=0,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_monthly = SST.time.values\n",
    "\n",
    "# Construct an xarray of days per month:\n",
    "n_days_array = cc.querying.getvar(control,'time_bounds',master_session,\n",
    "                 start_time=start_time, end_time=end_time,ncfile='ocean.nc')\n",
    "n_days_array = n_days_array.sel(time=slice(start_time,end_time))\n",
    "n_days_array = (n_days_array.isel(nv=1) - n_days_array.isel(nv=0))/60/60/24/1e9\n",
    "n_days_array = n_days_array.astype('int64')\n",
    "\n",
    "# Create an array with years:\n",
    "time_yearly = np.arange(int(start_time[0:4]), int(start_time[0:4])+ n_years, 1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to continental shelf region:\n",
    "SST  = shelf_mask_isobath(SST)[0]\n",
    "SSS_PSU = shelf_mask_isobath(SSS_PSU)[0]\n",
    "pot_rho_0 = shelf_mask_isobath(pot_rho_0)[0]\n",
    "net_sfc_heating = shelf_mask_isobath(net_sfc_heating)[0]\n",
    "pme_river = shelf_mask_isobath(pme_river)[0]\n",
    "salt_flux = shelf_mask_isobath(salt_flux)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to absolute salinity:\n",
    "# convert units to absolute salinity \n",
    "SSS = xr.DataArray(SA_from_SP(SSS_PSU,pressure,lon_t,lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'sea surface salinity', attrs = {'units':'Absolute Salinity (g/kg)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute salt transformation (no density binning)\n",
    "haline_contraction  = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "salt_transformation = haline_contraction * SSS * (pme_river - salt_flux) * n_days_array\n",
    "salt_transformation = salt_transformation.load()\n",
    "\n",
    "# Compute heat transformation (no density binning)\n",
    "thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "heat_transformation = thermal_expansion * net_sfc_heating * n_days_array\n",
    "heat_transformation = heat_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2150 done\n",
      "Year 2151 done\n",
      "Year 2152 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2153 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2154 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 13% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2155 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 12% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# Density binning sigma0:\n",
    "\n",
    "# Alter if density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "# sigma1:\n",
    "#isopycnal_bins = np.arange(32.25, 32.75, 0.01) \n",
    "# sigma0:\n",
    "isopycnal_bins = np.arange(27.5, 28.1, 0.04)\n",
    "\n",
    "bin_bottoms = isopycnal_bins[:-1]\n",
    "\n",
    "binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "for tt in range(n_years):\n",
    "    start_t = str(time_yearly[tt]) + '-01-01'\n",
    "    end_t   = str(time_yearly[tt]) + '-12-31'\n",
    "    salt_transformation_tmp = salt_transformation.sel(time=slice(start_t, end_t))\n",
    "    heat_transformation_tmp = heat_transformation.sel(time=slice(start_t, end_t))\n",
    "    pot_rho_0_tmp = pot_rho_0.sel(time=slice(start_t, end_t))\n",
    "                                                      \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_0_tmp.where(pot_rho_0_tmp <= isopycnal_bins[i+1]).where(pot_rho_0_tmp > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i,tt,:,:] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i,tt,:,:] = masked_transform\n",
    "    print('Year %i done'%time_yearly[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transformation sigma0:\n",
    "\n",
    "c_p = 3992.1\n",
    "isopycnal_bin_diff  = np.diff(isopycnal_bins)\n",
    "isopycnal_bin_mid   = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "\n",
    "# Will be overwritten in loop, this is just to get the dimensions etc\n",
    "salt_transformation_sigma0 = binned_salt_transformation\n",
    "heat_transformation_sigma0 = binned_heat_transformation\n",
    "\n",
    "salt_transformation_tmp = binned_salt_transformation / 365.\n",
    "heat_transformation_tmp = binned_heat_transformation / c_p / 365.\n",
    "\n",
    "# This procedure defines fluxes from lighter to denser classes as negative, we want the opposite\n",
    "salt_transformation_sigma0 = -1*salt_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "heat_transformation_sigma0 = -1*heat_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "#############################################################\n",
    "net_transformation_up1 = heat_transformation_sigma0 + salt_transformation_sigma0\n",
    "#############################################################\n",
    "\n",
    "# Rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "net_transformation_up1.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "ds = xr.Dataset({'net_transformation_up1': net_transformation_up1})\n",
    "outpath = '/g/data/v45/akm157/model_data/access-om2/'+easterlies_up_noDSW+'/SWMT/'+region+'_shelf_transformation_sigma0_'+time_period+'.nc'\n",
    "ds.to_netcdf(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conservative temperature\n",
    "SST = cc.querying.getvar(easterlies_down, 'surface_temp', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) - 273.15\n",
    "SST = SST.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Practical salinity, need to convert to absolute salinity\n",
    "SSS_PSU = cc.querying.getvar(easterlies_down, 'surface_salt', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "SSS_PSU = SSS_PSU.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Unfortunately net_sfc_heating diagnostic is incorrect/missing for these runs:\n",
    "#net_sfc_heating = cc.querying.getvar(easterlies_down, 'net_sfc_heating', easterlies_session, start_time=start_time, end_time=end_time)\n",
    "#net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "net_sfc_heating = cc.querying.getvar(easterlies_down, 'sfc_hflux_from_runoff', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_down, 'sfc_hflux_coupler', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_down, 'sfc_hflux_pme', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_down, 'frazil_3d_int_z', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc')\n",
    "net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Mass flux of precipitation - evaporation + river runoff\n",
    "pme_river = cc.querying.getvar(easterlies_down, 'pme_river', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "pme_river = pme_river.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Salt flux from ice and restoring:\n",
    "salt_flux = cc.querying.getvar(easterlies_down, 'sfc_salt_flux_ice', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) + \\\n",
    "            cc.querying.getvar(easterlies_down, 'sfc_salt_flux_restore', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "salt_flux = salt_flux.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Surface density:\n",
    "pot_rho_0 = cc.querying.getvar(easterlies_down, 'pot_rho_0', easterlies_session, ncfile='ocean.nc',start_time=start_time, end_time=end_time) - 1000\n",
    "pot_rho_0 = pot_rho_0.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice).sel(st_ocean=0,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_monthly = SST.time.values\n",
    "\n",
    "# Construct an xarray of days per month:\n",
    "n_days_array = cc.querying.getvar(control,'time_bounds',master_session,\n",
    "                 start_time=start_time, end_time=end_time,ncfile='ocean.nc')\n",
    "n_days_array = n_days_array.sel(time=slice(start_time,end_time))\n",
    "n_days_array = (n_days_array.isel(nv=1) - n_days_array.isel(nv=0))/60/60/24/1e9\n",
    "n_days_array = n_days_array.astype('int64')\n",
    "\n",
    "# Create an array with years:\n",
    "time_yearly = np.arange(int(start_time[0:4]), int(start_time[0:4])+ n_years, 1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to continental shelf region:\n",
    "SST  = shelf_mask_isobath(SST)[0]\n",
    "SSS_PSU = shelf_mask_isobath(SSS_PSU)[0]\n",
    "pot_rho_0 = shelf_mask_isobath(pot_rho_0)[0]\n",
    "net_sfc_heating = shelf_mask_isobath(net_sfc_heating)[0]\n",
    "pme_river = shelf_mask_isobath(pme_river)[0]\n",
    "salt_flux = shelf_mask_isobath(salt_flux)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to absolute salinity:\n",
    "# convert units to absolute salinity \n",
    "SSS = xr.DataArray(SA_from_SP(SSS_PSU,pressure,lon_t,lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'sea surface salinity', attrs = {'units':'Absolute Salinity (g/kg)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute salt transformation (no density binning)\n",
    "haline_contraction  = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "salt_transformation = haline_contraction * SSS * (pme_river - salt_flux) * n_days_array\n",
    "salt_transformation = salt_transformation.load()\n",
    "\n",
    "# Compute heat transformation (no density binning)\n",
    "thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "heat_transformation = thermal_expansion * net_sfc_heating * n_days_array\n",
    "heat_transformation = heat_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2150 done\n",
      "Year 2151 done\n",
      "Year 2152 done\n",
      "Year 2153 done\n",
      "Year 2154 done\n",
      "Year 2155 done\n",
      "Year 2156 done\n",
      "Year 2157 done\n",
      "Year 2158 done\n",
      "Year 2159 done\n",
      "Year 2160 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2161 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2162 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2163 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 11% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2164 done\n"
     ]
    }
   ],
   "source": [
    "# Density binning sigma0:\n",
    "\n",
    "# Alter if density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "# sigma1:\n",
    "#isopycnal_bins = np.arange(32.25, 32.75, 0.01) \n",
    "# sigma0:\n",
    "isopycnal_bins = np.arange(27.5, 28.1, 0.04)\n",
    "\n",
    "bin_bottoms = isopycnal_bins[:-1]\n",
    "\n",
    "binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "for tt in range(n_years):\n",
    "    start_t = str(time_yearly[tt]) + '-01-01'\n",
    "    end_t   = str(time_yearly[tt]) + '-12-31'\n",
    "    salt_transformation_tmp = salt_transformation.sel(time=slice(start_t, end_t))\n",
    "    heat_transformation_tmp = heat_transformation.sel(time=slice(start_t, end_t))\n",
    "    pot_rho_0_tmp = pot_rho_0.sel(time=slice(start_t, end_t))\n",
    "                                                      \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_0_tmp.where(pot_rho_0_tmp <= isopycnal_bins[i+1]).where(pot_rho_0_tmp > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i,tt,:,:] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i,tt,:,:] = masked_transform\n",
    "    print('Year %i done'%time_yearly[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transformation sigma0:\n",
    "\n",
    "c_p = 3992.1\n",
    "isopycnal_bin_diff  = np.diff(isopycnal_bins)\n",
    "isopycnal_bin_mid   = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "\n",
    "# Will be overwritten in loop, this is just to get the dimensions etc\n",
    "salt_transformation_sigma0 = binned_salt_transformation\n",
    "heat_transformation_sigma0 = binned_heat_transformation\n",
    "\n",
    "salt_transformation_tmp = binned_salt_transformation / 365.\n",
    "heat_transformation_tmp = binned_heat_transformation / c_p / 365.\n",
    "\n",
    "# This procedure defines fluxes from lighter to denser classes as negative, we want the opposite\n",
    "salt_transformation_sigma0 = -1*salt_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "heat_transformation_sigma0 = -1*heat_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "#############################################################\n",
    "net_transformation_up1 = heat_transformation_sigma0 + salt_transformation_sigma0\n",
    "#############################################################\n",
    "\n",
    "# Rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "net_transformation_up1.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "ds = xr.Dataset({'net_transformation_up1': net_transformation_up1})\n",
    "outpath = '/g/data/v45/akm157/model_data/access-om2/'+easterlies_down+'/SWMT/'+region+'_shelf_transformation_sigma0_'+time_period+'.nc'\n",
    "ds.to_netcdf(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up zonal perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# conservative temperature\n",
    "SST = cc.querying.getvar(easterlies_up_zonal, 'surface_temp', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) - 273.15\n",
    "SST = SST.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Practical salinity, need to convert to absolute salinity\n",
    "SSS_PSU = cc.querying.getvar(easterlies_up_zonal, 'surface_salt', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "SSS_PSU = SSS_PSU.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Unfortunately net_sfc_heating diagnostic is incorrect/missing for these runs:\n",
    "#net_sfc_heating = cc.querying.getvar(easterlies_up, 'net_sfc_heating', easterlies_session, start_time=start_time, end_time=end_time)\n",
    "#net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "net_sfc_heating = cc.querying.getvar(easterlies_up_zonal, 'sfc_hflux_from_runoff', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_zonal, 'sfc_hflux_coupler', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_zonal, 'sfc_hflux_pme', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_zonal, 'frazil_3d_int_z', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc')\n",
    "net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Mass flux of precipitation - evaporation + river runoff\n",
    "pme_river = cc.querying.getvar(easterlies_up_zonal, 'pme_river', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "pme_river = pme_river.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Salt flux from ice and restoring:\n",
    "salt_flux = cc.querying.getvar(easterlies_up_zonal, 'sfc_salt_flux_ice', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) + \\\n",
    "            cc.querying.getvar(easterlies_up_zonal, 'sfc_salt_flux_restore', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "salt_flux = salt_flux.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Surface density:\n",
    "pot_rho_0 = cc.querying.getvar(easterlies_up_zonal, 'pot_rho_0', easterlies_session, ncfile='ocean.nc',start_time=start_time, end_time=end_time) - 1000\n",
    "pot_rho_0 = pot_rho_0.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice).sel(st_ocean=0,method='nearest')\n",
    "\n",
    "# Coordinates\n",
    "lon_t = cc.querying.getvar(control,'geolon_t',master_session, n=1)\n",
    "lon_t = lon_t.sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "lat_t = cc.querying.getvar(control,'geolat_t',master_session, n=1)\n",
    "lat_t = lat_t.sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinate arrays:\n",
    "yt_ocean = SST.yt_ocean.values\n",
    "xt_ocean = SST.xt_ocean.values\n",
    "time_monthly = SST.time.values\n",
    "\n",
    "# Construct an xarray of days per month:\n",
    "n_days_array = cc.querying.getvar(control,'time_bounds',master_session,\n",
    "                 start_time=start_time, end_time=end_time,ncfile='ocean.nc')\n",
    "n_days_array = n_days_array.sel(time=slice(start_time,end_time))\n",
    "n_days_array = (n_days_array.isel(nv=1) - n_days_array.isel(nv=0))/60/60/24/1e9\n",
    "n_days_array = n_days_array.astype('int64')\n",
    "\n",
    "# Create an array with years:\n",
    "time_yearly = np.arange(int(start_time[0:4]), int(start_time[0:4])+len(SST.time)/12, 1).astype('int')\n",
    "n_years = len(time_yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to continental shelf region:\n",
    "SST  = shelf_mask_isobath(SST)[0]\n",
    "SSS_PSU = shelf_mask_isobath(SSS_PSU)[0]\n",
    "pot_rho_0 = shelf_mask_isobath(pot_rho_0)[0]\n",
    "net_sfc_heating = shelf_mask_isobath(net_sfc_heating)[0]\n",
    "pme_river = shelf_mask_isobath(pme_river)[0]\n",
    "salt_flux = shelf_mask_isobath(salt_flux)[0]\n",
    "lon_t   = shelf_mask_isobath(lon_t)[0]\n",
    "lat_t   = shelf_mask_isobath(lat_t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to absolute salinity:\n",
    "\n",
    "st_ocean = cc.querying.getvar(control,'st_ocean',master_session,n=1)\n",
    "depth = st_ocean[0].values\n",
    "depth_tile = (lat_t*0+1)*depth\n",
    "pressure = xr.DataArray(p_from_z(depth_tile,lat_t), coords = [yt_ocean, xt_ocean], dims = ['yt_ocean', 'xt_ocean'], name = 'pressure', attrs = {'units':'dbar'})\n",
    "    \n",
    "# convert units to absolute salinity \n",
    "SSS = xr.DataArray(SA_from_SP(SSS_PSU,pressure,lon_t,lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], \n",
    "                   name = 'sea surface salinity', \n",
    "                   attrs = {'units':'Absolute Salinity (g/kg)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute salt transformation (no density binning)\n",
    "haline_contraction  = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "salt_transformation = haline_contraction * SSS * (pme_river - salt_flux) * n_days_array\n",
    "salt_transformation = salt_transformation.load()\n",
    "\n",
    "# Compute heat transformation (no density binning)\n",
    "thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "heat_transformation = thermal_expansion * net_sfc_heating * n_days_array\n",
    "heat_transformation = heat_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2150 done\n",
      "Year 2151 done\n",
      "Year 2152 done\n",
      "Year 2153 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2154 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2155 done\n",
      "Year 2156 done\n"
     ]
    }
   ],
   "source": [
    "# Density binning sigma0:\n",
    "\n",
    "# Alter if density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "# sigma1:\n",
    "#isopycnal_bins = np.arange(32.25, 32.75, 0.01) \n",
    "# sigma0:\n",
    "isopycnal_bins = np.arange(27.5, 28.1, 0.04)\n",
    "\n",
    "bin_bottoms = isopycnal_bins[:-1]\n",
    "\n",
    "binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "for tt in range(n_years):\n",
    "    start_t = str(time_yearly[tt]) + '-01-01'\n",
    "    end_t   = str(time_yearly[tt]) + '-12-31'\n",
    "    salt_transformation_tmp = salt_transformation.sel(time=slice(start_t, end_t))\n",
    "    heat_transformation_tmp = heat_transformation.sel(time=slice(start_t, end_t))\n",
    "    pot_rho_0_tmp = pot_rho_0.sel(time=slice(start_t, end_t))\n",
    "                                                      \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_0_tmp.where(pot_rho_0_tmp <= isopycnal_bins[i+1]).where(pot_rho_0_tmp > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i,tt,:,:] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i,tt,:,:] = masked_transform\n",
    "    print('Year %i done'%time_yearly[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transformation sigma0:\n",
    "\n",
    "c_p = 3992.1\n",
    "isopycnal_bin_diff  = np.diff(isopycnal_bins)\n",
    "isopycnal_bin_mid   = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "\n",
    "# Will be overwritten in loop, this is just to get the dimensions etc\n",
    "salt_transformation_sigma0 = binned_salt_transformation\n",
    "heat_transformation_sigma0 = binned_heat_transformation\n",
    "\n",
    "salt_transformation_tmp = binned_salt_transformation / 365.\n",
    "heat_transformation_tmp = binned_heat_transformation / c_p / 365.\n",
    "\n",
    "# This procedure defines fluxes from lighter to denser classes as negative, we want the opposite\n",
    "salt_transformation_sigma0 = -1*salt_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "heat_transformation_sigma0 = -1*heat_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "#############################################################\n",
    "net_transformation_up1 = heat_transformation_sigma0 + salt_transformation_sigma0\n",
    "#############################################################\n",
    "\n",
    "# Rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "net_transformation_up1.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "ds = xr.Dataset({'net_transformation_up1': net_transformation_up1})\n",
    "outpath = '/g/data/v45/akm157/model_data/access-om2/'+easterlies_up_zonal+'/SWMT/'+region+'_shelf_transformation_sigma0_'+time_period+'.nc'\n",
    "ds.to_netcdf(outpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up meridional perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# conservative temperature\n",
    "SST = cc.querying.getvar(easterlies_up_meridional, 'surface_temp', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) - 273.15\n",
    "SST = SST.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Practical salinity, need to convert to absolute salinity\n",
    "SSS_PSU = cc.querying.getvar(easterlies_up_meridional, 'surface_salt', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "SSS_PSU = SSS_PSU.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Unfortunately net_sfc_heating diagnostic is incorrect/missing for these runs:\n",
    "#net_sfc_heating = cc.querying.getvar(easterlies_up, 'net_sfc_heating', easterlies_session, start_time=start_time, end_time=end_time)\n",
    "#net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "net_sfc_heating = cc.querying.getvar(easterlies_up_meridional, 'sfc_hflux_from_runoff', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_meridional, 'sfc_hflux_coupler', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_meridional, 'sfc_hflux_pme', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc') +\\\n",
    "                    cc.querying.getvar(easterlies_up_meridional, 'frazil_3d_int_z', easterlies_session, start_time=start_time, end_time=end_time,ncfile='ocean_month.nc')\n",
    "net_sfc_heating = net_sfc_heating.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Mass flux of precipitation - evaporation + river runoff\n",
    "pme_river = cc.querying.getvar(easterlies_up_meridional, 'pme_river', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "pme_river = pme_river.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "# Salt flux from ice and restoring:\n",
    "salt_flux = cc.querying.getvar(easterlies_up_meridional, 'sfc_salt_flux_ice', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time) + \\\n",
    "            cc.querying.getvar(easterlies_up_meridional, 'sfc_salt_flux_restore', easterlies_session, ncfile='ocean_month.nc',start_time=start_time, end_time=end_time)\n",
    "salt_flux = salt_flux.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice)\n",
    "\n",
    "# Surface density:\n",
    "pot_rho_0 = cc.querying.getvar(easterlies_up_meridional, 'pot_rho_0', easterlies_session, ncfile='ocean.nc',start_time=start_time, end_time=end_time) - 1000\n",
    "pot_rho_0 = pot_rho_0.sel(time=slice(start_time,end_time)).sel(yt_ocean=lat_slice).sel(xt_ocean=lon_slice).sel(st_ocean=0,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_monthly = SST.time.values\n",
    "\n",
    "# Construct an xarray of days per month:\n",
    "n_days_array = cc.querying.getvar(control,'time_bounds',master_session,\n",
    "                 start_time=start_time, end_time=end_time,ncfile='ocean.nc')\n",
    "n_days_array = n_days_array.sel(time=slice(start_time,end_time))\n",
    "n_days_array = (n_days_array.isel(nv=1) - n_days_array.isel(nv=0))/60/60/24/1e9\n",
    "n_days_array = n_days_array.astype('int64')\n",
    "\n",
    "# Create an array with years:\n",
    "time_yearly = np.arange(int(start_time[0:4]), int(start_time[0:4])+ n_years, 1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to continental shelf region:\n",
    "SST  = shelf_mask_isobath(SST)[0]\n",
    "SSS_PSU = shelf_mask_isobath(SSS_PSU)[0]\n",
    "pot_rho_0 = shelf_mask_isobath(pot_rho_0)[0]\n",
    "net_sfc_heating = shelf_mask_isobath(net_sfc_heating)[0]\n",
    "pme_river = shelf_mask_isobath(pme_river)[0]\n",
    "salt_flux = shelf_mask_isobath(salt_flux)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# convert to absolute salinity:\n",
    "# convert units to absolute salinity \n",
    "SSS = xr.DataArray(SA_from_SP(SSS_PSU,pressure,lon_t,lat_t), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'sea surface salinity', attrs = {'units':'Absolute Salinity (g/kg)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    }
   ],
   "source": [
    "# Compute salt transformation (no density binning)\n",
    "haline_contraction  = xr.DataArray(beta(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'saline contraction coefficient (constant conservative temp)', attrs = {'units':'kg/g'})\n",
    "salt_transformation = haline_contraction * SSS * (pme_river - salt_flux) * n_days_array\n",
    "salt_transformation = salt_transformation.load()\n",
    "\n",
    "# Compute heat transformation (no density binning)\n",
    "thermal_expansion = xr.DataArray(alpha(SSS, SST, pressure), coords = [time_monthly, yt_ocean, xt_ocean], dims = ['time','yt_ocean', 'xt_ocean'], name = 'thermal expansion coefficient (constant conservative temp)', attrs = {'units':'1/K'})\n",
    "heat_transformation = thermal_expansion * net_sfc_heating * n_days_array\n",
    "heat_transformation = heat_transformation.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2150 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2151 done\n",
      "Year 2152 done\n",
      "Year 2153 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2154 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2155 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n",
      "distributed.utils_perf - WARNING - full garbage collections took 10% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2156 done\n"
     ]
    }
   ],
   "source": [
    "# Density binning sigma0:\n",
    "\n",
    "# Alter if density range doesn't capture surface processes in your study region, or if a different density field (not sigma1) is used\n",
    "# sigma1:\n",
    "#isopycnal_bins = np.arange(32.25, 32.75, 0.01) \n",
    "# sigma0:\n",
    "isopycnal_bins = np.arange(27.5, 28.1, 0.04)\n",
    "\n",
    "bin_bottoms = isopycnal_bins[:-1]\n",
    "\n",
    "binned_salt_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'salt transformation in isopycnal bins summed over time')\n",
    "binned_salt_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "binned_heat_transformation = xr.DataArray(np.zeros((len(bin_bottoms), n_years, len(yt_ocean), len(xt_ocean))), coords = [bin_bottoms, time_yearly, yt_ocean, xt_ocean], dims = ['isopycnal_bins', 'year', 'yt_ocean', 'xt_ocean'], name = 'heat transformation in isopycnal bins summed over time')\n",
    "binned_heat_transformation.chunk({'isopycnal_bins':1})\n",
    "\n",
    "for tt in range(n_years):\n",
    "    start_t = str(time_yearly[tt]) + '-01-01'\n",
    "    end_t   = str(time_yearly[tt]) + '-12-31'\n",
    "    salt_transformation_tmp = salt_transformation.sel(time=slice(start_t, end_t))\n",
    "    heat_transformation_tmp = heat_transformation.sel(time=slice(start_t, end_t))\n",
    "    pot_rho_0_tmp = pot_rho_0.sel(time=slice(start_t, end_t))\n",
    "                                                      \n",
    "    for i in range(len(isopycnal_bins)-1):\n",
    "        bin_mask = pot_rho_0_tmp.where(pot_rho_0_tmp <= isopycnal_bins[i+1]).where(pot_rho_0_tmp > isopycnal_bins[i]) * 0 + 1\n",
    "        masked_transform = (salt_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0) \n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_salt_transformation[i,tt,:,:] = masked_transform\n",
    "\n",
    "        masked_transform = (heat_transformation_tmp * bin_mask).sum(dim = 'time') \n",
    "        masked_transform = masked_transform.where(masked_transform != 0)\n",
    "        masked_transform = masked_transform.load()\n",
    "        binned_heat_transformation[i,tt,:,:] = masked_transform\n",
    "    print('Year %i done'%time_yearly[tt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate transformation sigma0:\n",
    "\n",
    "c_p = 3992.1\n",
    "isopycnal_bin_diff  = np.diff(isopycnal_bins)\n",
    "isopycnal_bin_mid   = (isopycnal_bins[1:] + isopycnal_bins[:-1])/2\n",
    "\n",
    "# Will be overwritten in loop, this is just to get the dimensions etc\n",
    "salt_transformation_sigma0 = binned_salt_transformation\n",
    "heat_transformation_sigma0 = binned_heat_transformation\n",
    "\n",
    "salt_transformation_tmp = binned_salt_transformation / 365.\n",
    "heat_transformation_tmp = binned_heat_transformation / c_p / 365.\n",
    "\n",
    "# This procedure defines fluxes from lighter to denser classes as negative, we want the opposite\n",
    "salt_transformation_sigma0 = -1*salt_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "heat_transformation_sigma0 = -1*heat_transformation_tmp/isopycnal_bin_diff[:,np.newaxis,np.newaxis,np.newaxis]\n",
    "\n",
    "#############################################################\n",
    "net_transformation_up1 = heat_transformation_sigma0 + salt_transformation_sigma0\n",
    "#############################################################\n",
    "\n",
    "# Rename the isopycnal bin (bottom edge) coord with the isopycnal bin midpoints...\n",
    "net_transformation_up1.coords['isopycnal_bins'] = isopycnal_bin_mid\n",
    "ds = xr.Dataset({'net_transformation_up1': net_transformation_up1})\n",
    "outpath = '/g/data/v45/akm157/model_data/access-om2/'+easterlies_up_meridional+'/SWMT/'+region+'_shelf_transformation_sigma0_'+time_period+'.nc'\n",
    "ds.to_netcdf(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-21.04]",
   "language": "python",
   "name": "conda-env-analysis3-21.04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
